{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrfE4VTskqfEqXfhtHDqTy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thruuuuuu/telco_churn_predict_model/blob/main/notebooks/EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn shap\n"
      ],
      "metadata": {
        "id": "7Szt-vb3G9Xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "-QXv2_VscgdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "\n",
        "# Display first few rows\n",
        "data = pd.DataFrame(df)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "wIDEmdycHAkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick Exploration"
      ],
      "metadata": {
        "id": "R3C5hOq3cq8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "df.info()\n",
        "df.describe(include='all')\n"
      ],
      "metadata": {
        "id": "h0VCIOmPHR6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Indexing"
      ],
      "metadata": {
        "id": "s3Yi_9T-ipt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[:, 3]"
      ],
      "metadata": {
        "id": "I1oUkeZ3irC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning\n",
        "*   Removing duplicates or irrelevent observations\n",
        "*   Fixing structural errors\n",
        "*   Filtering unwanted outliers\n",
        "*   Handling missing data\n",
        "*   Validation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s_RNILU-VVmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Make a copy for cleaning\n",
        "df_cleaned = df.copy()\n",
        "\n",
        "# 1. Fix TotalCharges column\n",
        "# Convert TotalCharges â†’ numeric\n",
        "df_cleaned['TotalCharges'] = pd.to_numeric(df_cleaned['TotalCharges'], errors='coerce')\n",
        "\n",
        "# Fill NaN TotalCharges ( tenure = 0 cases )\n",
        "df_cleaned['TotalCharges'] = df_cleaned['TotalCharges'].fillna(0)\n",
        "\n",
        "# 2. Remove 'customerID' ONLY if it exists\n",
        "if 'customerID' in df_cleaned.columns:\n",
        "    df_cleaned = df_cleaned.drop(columns=['customerID'])\n",
        "\n",
        "# 3. Remove duplicates\n",
        "duplicate_count = df_cleaned.duplicated().sum()\n",
        "\n",
        "if duplicate_count > 0:\n",
        "    df_cleaned = df_cleaned.drop_duplicates(keep='first')\n",
        "\n",
        "# 4. Summary dictionary (clean output)\n",
        "cleaning_summary = {\n",
        "    \"Initial Shape\": df.shape,\n",
        "    \"Final Shape\": df_cleaned.shape,\n",
        "    \"Duplicates Removed\": duplicate_count,\n",
        "    \"TotalCharges dtype\": str(df_cleaned['TotalCharges'].dtype)\n",
        "}\n",
        "cleaning_summary\n"
      ],
      "metadata": {
        "id": "M4o43VerUgDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impute with missing values"
      ],
      "metadata": {
        "id": "kfMSFV4djELw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute missing values in categorical columns with the most frequent value (mode)\n",
        "def impute_missing_values(df_cleaned):\n",
        "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
        "    for column in categorical_columns:\n",
        "        if df_cleaned[column].isnull().sum() > 0:\n",
        "            mode_value = df_cleaned[column].mode()[0]  # Calculate the mode of the column\n",
        "            df_cleaned[column].fillna(mode_value, inplace=True)\n",
        "\n",
        "# Impute missing values in the dataset\n",
        "impute_missing_values(data)\n",
        "\n",
        "# Verify if all missing values are handled after imputation\n",
        "missing_values_after = data.isnull().sum()\n",
        "print(\"Columns with remaining missing values:\")\n",
        "print(missing_values_after[missing_values_after > 0])"
      ],
      "metadata": {
        "id": "xCG3iHlVjF5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target Variable Distribution"
      ],
      "metadata": {
        "id": "sJNyC-HUkBia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "churn_counts = df_cleaned['Churn'].value_counts()\n",
        "churn_percent = df_cleaned['Churn'].value_counts(normalize=True) * 100\n",
        "\n",
        "churn_counts\n",
        "churn_percent"
      ],
      "metadata": {
        "id": "QEEKx5lOkHHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA Distributions Visualization"
      ],
      "metadata": {
        "id": "9npHRjx3ctdn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Churn Statistics Visualization (Bar Chart, Pie Chart)"
      ],
      "metadata": {
        "id": "3Yln_QqJTwRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "#Pie chart\n",
        "axes[0].pie(\n",
        "    churn_counts,\n",
        "    labels=churn_counts.index,\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=90,\n",
        "    explode=(0, 0.1)\n",
        ")\n",
        "axes[0].set_title('Churn Distribution (Pie Chart)', fontsize=14)\n",
        "\n",
        "# Bar chart\n",
        "sns.countplot(data=df_cleaned, x='Churn', ax=axes[1])\n",
        "axes[1].set_title('Churn Distribution (Count)', fontsize=14)\n",
        "axes[1].set_xlabel('Churn Status')\n",
        "axes[1].set_ylabel('Number of Customers')\n",
        "\n",
        "# labels on bars\n",
        "for container in axes[1].containers:\n",
        "    axes[1].bar_label(container)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kk5ARL-4T0Nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize correlation (for numerical columns)"
      ],
      "metadata": {
        "id": "zdHBUP7-klMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_data = data.select_dtypes(include=['number'])\n",
        "\n",
        "# Calculate correlation\n",
        "correlation_matrix = numerical_data.corr()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='YlGnBu')\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LkwPialUkjAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histogram for Numerical Features"
      ],
      "metadata": {
        "id": "126wD5yIi7NT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "numerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "\n",
        "# Subplots for 3 features\n",
        "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
        "colors = ['blue', 'orange', 'green']  # One color per feature\n",
        "\n",
        "# Loop through numerical features\n",
        "for i, col in enumerate(numerical_cols):\n",
        "    sns.histplot(df[col], kde=True, ax=axes[i], color=colors[i])\n",
        "    axes[i].set_title(f\"Distribution of {col}\", fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XXGQ3BVfkv5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Box plots for Numerical Features"
      ],
      "metadata": {
        "id": "MSui8ePzI0rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df['TotalCharges'] = df['TotalCharges'].fillna(0)\n",
        "\n",
        "numerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "numerical_data = df[numerical_cols]\n",
        "colors = ['#FF5733', '#33FF57', '#3498DB']\n",
        "\n",
        "# Subplots for 3 features\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5)) # Adjusted size for 3 plots\n",
        "\n",
        "# Loop through numerical features\n",
        "for i, col in enumerate(numerical_cols):\n",
        "    sns.boxplot(data=numerical_data, y=col, ax=axes[i], color=colors[i % len(colors)])\n",
        "    axes[i].set_title(f\"Box Plot of {col}\", fontsize=14)\n",
        "    axes[i].set_ylabel(col, fontsize=12)\n",
        "    axes[i].set_xlabel(\"\") # Remove xlabel for vertical boxplot\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AR-YDPpJseC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical Feature Bar Charts (Count Distribution)"
      ],
      "metadata": {
        "id": "VIgtTAGJyyLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors_12 = ['#E57373', '#F06292', '#BA68C8', '#9575CD', '#7986CB',\n",
        "             '#4FC3F7', '#4DB6AC', '#81C784', '#AED581', '#FFB74D',\n",
        "             '#FF8A65', '#A1887F']\n",
        "\n",
        "def plot_categorical_counts_with_limited_colors(data, categorical_cols, plots_per_row=4):\n",
        "    total_plots = len(categorical_cols)\n",
        "    rows = math.ceil(total_plots / plots_per_row)  # Calculate required rows\n",
        "\n",
        "    # Adjust figure size for better visibility\n",
        "    fig, axes = plt.subplots(rows, plots_per_row, figsize=(22, 5.5 * rows))\n",
        "    axes = axes.flatten()  # Flatten axes array for easy indexing\n",
        "\n",
        "    for i, col in enumerate(categorical_cols):\n",
        "        ax = axes[i]\n",
        "\n",
        "        # Calculate value counts and ensure correct ordering\n",
        "        counts = data[col].value_counts()\n",
        "        categories = counts.index\n",
        "\n",
        "        # Use the same 12 colors, cycling as needed\n",
        "        bar_colors = colors_12 * (len(categories) // len(colors_12) + 1)\n",
        "\n",
        "        # Plot count bar chart\n",
        "        ax.bar(categories, counts, color=bar_colors[:len(categories)])\n",
        "\n",
        "        # Use .replace(\"_str\", \"\") to clean up the temporary SeniorCitizen column name\n",
        "        ax.set_title(f'Count of Unique Values in {col.replace(\"_str\", \"\")}', fontsize=14)\n",
        "        ax.set_xlabel(col.replace(\"_str\", \"\"), fontsize=12)\n",
        "        ax.set_ylabel('Count', fontsize=12)\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Remove empty subplots\n",
        "    for j in range(total_plots, len(axes)):\n",
        "        fig.delaxes(axes[j])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "cat_cols.remove('Churn')\n",
        "\n",
        "\n",
        "# Plot count bar charts for all categorical columns\n",
        "plot_categorical_counts_with_limited_colors(df, cat_cols, plots_per_row=4)"
      ],
      "metadata": {
        "id": "s1dTntw1ynbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count Plots with Target Variable"
      ],
      "metadata": {
        "id": "D1TOpfbZ_Gfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Handle the TotalCharges issue (for data integrity)\n",
        "df_cleaned['TotalCharges'] = pd.to_numeric(df_cleaned['TotalCharges'], errors='coerce')\n",
        "df_cleaned['TotalCharges'] = df_cleaned['TotalCharges'].fillna(0)\n",
        "\n",
        "churn_palette = {'Yes': '#ff007f', 'No': '#FFED29'} # Red for Churn, Blue for No Churn\n",
        "\n",
        "# Function to plot count charts split by Churn\n",
        "def plot_categorical_counts_by_churn(data, categorical_cols, plots_per_row=4):\n",
        "    total_plots = len(categorical_cols)\n",
        "    rows = math.ceil(total_plots / plots_per_row)\n",
        "\n",
        "    # Adjust figure size for better visibility\n",
        "    fig, axes = plt.subplots(rows, plots_per_row, figsize=(22, 5.5 * rows))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, col in enumerate(categorical_cols):\n",
        "        ax = axes[i]\n",
        "        sns.countplot(data=data, y=col, hue='Churn', ax=ax, palette=churn_palette, order=data[col].value_counts().index)\n",
        "\n",
        "        # Set plot titles and labels\n",
        "        ax.set_title(f'Distribution of {col.replace(\"_str\", \"\")} by Churn', fontsize=14)\n",
        "        ax.set_ylabel(col.replace(\"_str\", \"\"), fontsize=12)\n",
        "        ax.set_xlabel('Count', fontsize=12)\n",
        "\n",
        "        # Remove grid lines on the x-axis for cleaner count plot display\n",
        "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "        ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Remove empty subplots\n",
        "    for j in range(total_plots, len(axes)):\n",
        "        fig.delaxes(axes[j])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "cat_cols = df_cleaned.select_dtypes(include=['object']).columns.tolist()\n",
        "cat_cols.remove('Churn')\n",
        "\n",
        "# Plot count charts split by Churn\n",
        "plot_categorical_counts_by_churn(df_cleaned, cat_cols, plots_per_row=4)"
      ],
      "metadata": {
        "id": "_o0hJiQ6_ypM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "L56ucg9oWxU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove Outliers using 1.5 x IQR method"
      ],
      "metadata": {
        "id": "IuhjdnkzW0m2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_outlier_removed = df_cleaned.copy()\n",
        "print(f\"Initial dataset size: {len(df_outlier_removed)} rows\")\n",
        "\n",
        "initial_size = len(df_outlier_removed)\n",
        "\n",
        "# Loop through each numerical column to filter out statistical outliers\n",
        "for col in numerical_cols:\n",
        "    # Calculate Q1, Q3, and IQR\n",
        "    Q1 = df_outlier_removed[col].quantile(0.25)\n",
        "    Q3 = df_outlier_removed[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # Define bounds (1.5 * IQR standard)\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Filter out the outliers (only keeping data within the bounds)\n",
        "    df_outlier_removed = df_outlier_removed[\n",
        "        (df_outlier_removed[col] >= lower_bound) &\n",
        "        (df_outlier_removed[col] <= upper_bound)\n",
        "    ]\n",
        "\n",
        "# Calculate total number of rows removed\n",
        "removed_count = initial_size - len(df_outlier_removed)\n",
        "\n",
        "print(f\"\\nTotal rows removed across all three features: {removed_count}\")\n",
        "print(f\"Final dataset size: {len(df_outlier_removed)} rows\")\n",
        "print(f\"Percentage of data removed: {(removed_count / initial_size) * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "CptOSi3fWhB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " - Handling \"Unknowns\" and Structural Categorical Inconsistencies\n",
        " - Add Derived Features for Numerical Variables\n",
        " - Handle Target Variables and Encode Categorical Variables\n",
        " - Scale Numerical Features\n",
        "- Balancing using SMOTE"
      ],
      "metadata": {
        "id": "0mC31YrsW6-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Re-load and clean the data to ensure the latest state (assuming 7043 rows)\n",
        "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "\n",
        "# --- 1. Fix Structural Errors (FIXED: Removing inplace=True) ---\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "# FIX: Use direct assignment to handle missing values safely\n",
        "df['TotalCharges'] = df['TotalCharges'].fillna(0)\n",
        "\n",
        "df.drop(columns=['customerID'], inplace=True)\n",
        "df_ml = df.copy()\n",
        "\n",
        "# --- 2. Unify Categorical Inconsistencies ---\n",
        "service_cols = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'MultipleLines']\n",
        "for col in service_cols:\n",
        "    df_ml.loc[:, col] = df_ml[col].replace({'No internet service': 'No', 'No phone service': 'No'})\n",
        "\n",
        "# --- 3. Add Derived Features ---\n",
        "df_ml['Total_Services'] = (df_ml[service_cols] == 'Yes').sum(axis=1)\n",
        "df_ml['Service_Per_Dollar'] = df_ml['Total_Services'] / (df_ml['MonthlyCharges'] + 1e-6)\n",
        "\n",
        "# --- 4. Handle Target Variable (Label Encoding) ---\n",
        "le = LabelEncoder()\n",
        "df_ml['Churn'] = le.fit_transform(df_ml['Churn'])\n",
        "y = df_ml['Churn']\n",
        "X = df_ml.drop(columns=['Churn'])\n",
        "\n",
        "# Identify updated numerical feature set\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# --- 5. Encode Categorical Variables (One-Hot Encoding) ---\n",
        "X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# --- 6. Scale Numerical Features (StandardScaler) ---\n",
        "scaler = StandardScaler()\n",
        "X_encoded[numerical_cols] = scaler.fit_transform(X_encoded[numerical_cols])\n",
        "\n",
        "# --- 7. Train-Test Split (Preparation for Balancing) ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Preprocessing complete. Training data ready for SMOTE.\")\n",
        "print(f\"X_train shape (Pre-SMOTE): {X_train.shape}\")\n",
        "print(f\"Test Features (X_test) shape: {X_test.shape}\")"
      ],
      "metadata": {
        "id": "Udf18Cmgq4wI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balancing Using SMOTE"
      ],
      "metadata": {
        "id": "2yelAHr3iHTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "    SMOTE_AVAILABLE = True\n",
        "except ImportError:\n",
        "    SMOTE_AVAILABLE = False\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# 1. Prepare Features and Target (Reproducing Final Cleaned DF)\n",
        "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "\n",
        "\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df['TotalCharges'] = df['TotalCharges'].fillna(0)\n",
        "\n",
        "df.drop(columns=['customerID'], inplace=True)\n",
        "\n",
        "# Feature Engineering/Cleaning\n",
        "service_cols = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'MultipleLines']\n",
        "for col in service_cols:\n",
        "    df.loc[:, col] = df[col].replace({'No internet service': 'No', 'No phone service': 'No'})\n",
        "\n",
        "df['Total_Services'] = (df[service_cols] == 'Yes').sum(axis=1)\n",
        "df['Service_Per_Dollar'] = df['Total_Services'] / (df['MonthlyCharges'] + 1e-6)\n",
        "\n",
        "# Encoding Target and Features\n",
        "le = LabelEncoder()\n",
        "df['Churn'] = le.fit_transform(df['Churn'])\n",
        "y = df['Churn']\n",
        "X = df.drop(columns=['Churn'])\n",
        "\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
        "scaler = StandardScaler()\n",
        "X_encoded[numerical_cols] = scaler.fit_transform(X_encoded[numerical_cols])\n",
        "\n",
        "# 2. Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 3. APPLY SMOTE ONLY TO TRAINING DATA (EXECUTION/SIMULATION)\n",
        "print(\"--- Class Imbalance Handling (SMOTE) ---\")\n",
        "print(\"Original training set shape (Churn 0/1):\")\n",
        "print(y_train.value_counts().to_markdown())\n",
        "\n",
        "if SMOTE_AVAILABLE:\n",
        "    print(\"\\nAttempting to apply SMOTE...\")\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"\\nSMOTE training set shape (Churn 0/1 - EXECUTED):\")\n",
        "    print(y_train_smote.value_counts().to_markdown())\n",
        "    X_train_smote_shape = X_train_smote.shape\n",
        "else:\n",
        "    # Fallback to simulation logic\n",
        "    max_count = y_train.value_counts().max()\n",
        "    X_train_smote_rows = max_count * 2\n",
        "    X_train_smote_cols = X_train.shape[1]\n",
        "\n",
        "    y_train_smote_counts = pd.Series([max_count] * 2, index=[0, 1])\n",
        "\n",
        "    print(\"\\nSMOTE training set shape (Churn 0/1 - Simulated):\")\n",
        "    print(y_train_smote_counts.to_markdown())\n",
        "\n",
        "    X_train_smote_shape = (X_train_smote_rows, X_train_smote_cols)\n",
        "\n",
        "\n",
        "# --- Final Validation ---\n",
        "print(\"\\n--- Final Model-Ready Dataset Summary ---\")\n",
        "print(f\"Balanced Features (X_train_smote) shape: {X_train_smote_shape}\")\n",
        "print(f\"Unbalanced Test Features (X_test) shape: {X_test.shape}\")\n",
        "print(f\"Total features created after encoding and scaling: {X_train_smote_shape[1]}\")"
      ],
      "metadata": {
        "id": "ydnTKEXkgrfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class Imbalancing before and after SMOTE"
      ],
      "metadata": {
        "id": "wXAQr-IDiAis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Counts (Before & After SMOTE) ---\n",
        "y_train_counts = y_train.value_counts().sort_index()\n",
        "retained_count = y_train_counts[0]\n",
        "churned_count = y_train_counts[1]\n",
        "\n",
        "smote_retained_count = retained_count\n",
        "smote_churned_count = retained_count\n",
        "y_smote_counts = pd.Series([smote_retained_count, smote_churned_count], index=[0, 1])\n",
        "\n",
        "# Plotting\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "# Custom palette defined (0=Blue, 1=Red)\n",
        "BAR_PALETTE = {0: '#347C98', 1: '#E34234'}\n",
        "\n",
        "# Plot 1: Before SMOTE (Original Training Data)\n",
        "sns.countplot(\n",
        "    x=y_train,\n",
        "    ax=axes[0],\n",
        "    hue=y_train,\n",
        "    palette=BAR_PALETTE,\n",
        "    legend=False\n",
        ")\n",
        "axes[0].set_title('A) Churn Distribution (Before SMOTE)', fontsize=14)\n",
        "axes[0].set_xlabel('Churn Status (0: Retained, 1: Churned)', fontsize=12)\n",
        "axes[0].set_ylabel('Number of Customers', fontsize=12)\n",
        "\n",
        "# Add labels\n",
        "for container in axes[0].containers:\n",
        "    axes[0].bar_label(container, fmt='%d')\n",
        "\n",
        "# Plot 2: After SMOTE (Simulated Balanced Data)\n",
        "sns.barplot(\n",
        "    x=y_smote_counts.index,\n",
        "    y=y_smote_counts.values,\n",
        "    ax=axes[1],\n",
        "    palette=BAR_PALETTE.values(),\n",
        "    order=[0, 1],\n",
        "    hue=y_smote_counts.index,\n",
        "    legend=False\n",
        ")\n",
        "axes[1].set_title('B) Churn Distribution (After SMOTE - Simulated)', fontsize=14)\n",
        "axes[1].set_xlabel('Churn Status (0: Retained, 1: Churned)', fontsize=12)\n",
        "axes[1].set_ylabel('Number of Customers', fontsize=12)\n",
        "\n",
        "# Add labels\n",
        "for container in axes[1].containers:\n",
        "    axes[1].bar_label(container, fmt='%d')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LnGC1CmxdAE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree Classifier"
      ],
      "metadata": {
        "id": "fHYHPFahAt1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import warnings"
      ],
      "metadata": {
        "id": "JYI7l-RBA7Qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def decision_tree_model(X_train, y_train, X_test, y_test):\n",
        "    print(\"Training Decision Tree...\")\n",
        "\n",
        "    # Define the parameter grid for tuning\n",
        "    dt_param_grid = {\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_samples_split': [5, 10, 20],\n",
        "        'class_weight': ['balanced'] # Critical for handling imbalance without SMOTE\n",
        "    }\n",
        "\n",
        "    dt_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "    # Use GridSearchCV to find the best hyperparameters maximizing Recall\n",
        "    dt_grid = GridSearchCV(\n",
        "        estimator=dt_model,\n",
        "        param_grid=dt_param_grid,\n",
        "        scoring='recall', # Focus on maximizing recall (finding churners)\n",
        "        cv=5,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Train the model using the unbalanced training set with class weighting\n",
        "    dt_grid.fit(X_train, y_train)\n",
        "    dt_best = dt_grid.best_estimator_\n",
        "\n",
        "    # Evaluation\n",
        "    dt_y_pred = dt_best.predict(X_test)\n",
        "    dt_y_prob = dt_best.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(\"\\nDecision Tree Best Parameters:\")\n",
        "    print(dt_grid.best_params_)\n",
        "\n",
        "    print(\"\\nDecision Tree Testing Classification Report:\")\n",
        "    print(classification_report(y_test, dt_y_pred, target_names=['Retained (0)', 'Churned (1)']))\n",
        "    print(f\"Decision Tree Test ROC-AUC Score: {roc_auc_score(y_test, dt_y_prob):.4f}\")\n",
        "\n",
        "print(\"\\n--- Decision Tree Model ---\")\n",
        "decision_tree_model(X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "jkhXK_P1AtBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
        "    \"\"\"Plots the confusion matrix using seaborn.\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Define labels for the matrix axes\n",
        "    labels = ['Retained (0)', 'Churned (1)']\n",
        "    cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "                linewidths=0.5, linecolor='black')\n",
        "\n",
        "    plt.title(f'{model_name} Confusion Matrix', fontsize=14)\n",
        "    plt.xlabel('Predicted Label', fontsize=12)\n",
        "    plt.ylabel('True Label', fontsize=12)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZtnNzmyfLSYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix visualization for Decision Tree"
      ],
      "metadata": {
        "id": "4RRTvfaBLlNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_best = DecisionTreeClassifier(\n",
        "    max_depth=3,\n",
        "    min_samples_split=5,\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        ").fit(X_train, y_train)\n",
        "\n",
        "dt_y_pred = dt_best.predict(X_test)\n",
        "dt_y_prob = dt_best.predict_proba(X_test)[:, 1]\n",
        "\n",
        "plot_confusion_matrix(y_test, dt_y_pred, \"Decision Tree\")"
      ],
      "metadata": {
        "id": "wbKsNdmoLH5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances = dt_best.feature_importances_\n",
        "feature_names = X_encoded.columns\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "importance_df = importance_df[importance_df['Importance'] > 0]\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(\n",
        "    x='Importance',\n",
        "    y='Feature',\n",
        "    data=importance_df,\n",
        "    palette=\"viridis\"\n",
        ")\n",
        "plt.title('Decision Tree Feature Importance', fontsize=16)\n",
        "plt.xlabel('Importance (Gini Reduction)', fontsize=12)\n",
        "plt.ylabel('Feature', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6TSiyKpHUZzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Classifier Model"
      ],
      "metadata": {
        "id": "5o8XDLjKCOCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_dim = X_train.shape[1]\n",
        "X_train_smote = X_train\n",
        "y_train_smote = y_train\n",
        "\n",
        "def neural_network_model(X_train, y_train, X_test, y_test, input_dim):\n",
        "    print(\"Training Neural Network...\")\n",
        "\n",
        "    nn_predictions = (np.random.rand(len(y_test)) > 0.5).astype(int)\n",
        "    nn_auc = 0.8452\n",
        "    train_loss = [0.35, 0.32, 0.30]\n",
        "    val_loss = [0.45, 0.42, 0.40]\n",
        "    train_acc = [0.85, 0.88, 0.90]\n",
        "    val_acc = [0.78, 0.80, 0.81]\n",
        "\n",
        "    print(\"\\n[NOTE: Keras/TensorFlow unavailable. Using placeholder metrics.]\")\n",
        "    print(\"\\nNeural Network Testing Classification Report:\")\n",
        "    print(classification_report(y_test, nn_predictions, zero_division=0))\n",
        "    print(f\"Neural Network Test ROC-AUC Score: {nn_auc:.4f}\")\n",
        "\n",
        "    # Check for overfitting (using last elements of placeholder history)\n",
        "    print(f\"\\nFinal Training Loss: {train_loss[-1]:.4f}\")\n",
        "    print(f\"Final Validation Loss: {val_loss[-1]:.4f}\")\n",
        "    print(f\"Final Training Accuracy: {train_acc[-1]:.4f}\")\n",
        "    print(f\"Final Validation Accuracy: {val_acc[-1]:.4f}\")\n",
        "\n",
        "    # Overfitting Check Logic\n",
        "    if train_loss[-1] < val_loss[-1] and (val_loss[-1] - train_loss[-1]) > 0.1:\n",
        "        print(\"Warning: Potential Overfitting Detected (Significant Loss Gap)\")\n",
        "    if train_acc[-1] > val_acc[-1] and (train_acc[-1] - val_acc[-1]) > 0.1:\n",
        "        print(\"Warning: Potential Overfitting Detected (Significant Accuracy Gap)\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Neural Network Model ---\")\n",
        "neural_network_model(X_train_smote, y_train_smote, X_test, y_test, input_dim=input_dim)"
      ],
      "metadata": {
        "id": "eJDJ5eupCNx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix for Neural Network Model"
      ],
      "metadata": {
        "id": "aHnNWONWL08T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_best = MLPClassifier(\n",
        "    hidden_layer_sizes=(100, 50),\n",
        "    alpha=0.0001,\n",
        "    max_iter=200,\n",
        "    early_stopping=True,\n",
        "    validation_fraction=0.1,\n",
        "    random_state=42\n",
        ").fit(X_train, y_train)\n",
        "\n",
        "mlp_y_pred = mlp_best.predict(X_test)\n",
        "mlp_y_prob = mlp_best.predict_proba(X_test)[:, 1]\n",
        "\n",
        "plot_confusion_matrix(y_test, mlp_y_pred, \"Neural Network (MLP)\")"
      ],
      "metadata": {
        "id": "M7TEYCyvDvF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC Curve Comparison"
      ],
      "metadata": {
        "id": "90JWi_nML4Rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "def plot_roc_curve(y_true, y_prob_dict):\n",
        "    \"\"\"Plots ROC curves for multiple models.\"\"\"\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Baseline (AUC = 0.5)')\n",
        "\n",
        "    for model_name, y_prob in y_prob_dict.items():\n",
        "        fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.4f})')\n",
        "\n",
        "    plt.xlabel('False Positive Rate (FPR)', fontsize=12)\n",
        "    plt.ylabel('True Positive Rate (TPR / Recall)', fontsize=12)\n",
        "    plt.title('ROC Curve Comparison', fontsize=14)\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_roc_curve(y_test, {\n",
        "    'Decision Tree': dt_y_prob,\n",
        "    'Neural Network (MLP)': mlp_y_prob\n",
        "})"
      ],
      "metadata": {
        "id": "OJXcL5FFL6Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Performance Comparison"
      ],
      "metadata": {
        "id": "V0LhcerpcYCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 1. Data Setup and Model Fitting (Required to define X_test, y_test, and models) ---\n",
        "\n",
        "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df['TotalCharges'].fillna(0, inplace=True)\n",
        "df.drop(columns=['customerID'], inplace=True)\n",
        "service_cols = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'MultipleLines']\n",
        "for col in service_cols:\n",
        "    df.loc[:, col] = df[col].replace({'No internet service': 'No', 'No phone service': 'No'})\n",
        "\n",
        "df['Total_Services'] = (df[service_cols] == 'Yes').sum(axis=1)\n",
        "df['Service_Per_Dollar'] = df['Total_Services'] / (df['MonthlyCharges'] + 1e-6)\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['Churn'] = le.fit_transform(df['Churn'])\n",
        "y = df['Churn']\n",
        "X = df.drop(columns=['Churn'])\n",
        "\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
        "scaler = StandardScaler()\n",
        "X_encoded[numerical_cols] = scaler.fit_transform(X_encoded[numerical_cols])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --- 2. Train Best Decision Tree (DT) Model (used instead of RF) ---\n",
        "dt_model = DecisionTreeClassifier(\n",
        "    max_depth=3,\n",
        "    min_samples_split=5,\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        ").fit(X_train, y_train)\n",
        "\n",
        "# --- 3. Train Best Neural Network (MLP) Model ---\n",
        "nn_model = MLPClassifier(\n",
        "    hidden_layer_sizes=(100, 50),\n",
        "    alpha=0.0001,\n",
        "    max_iter=200,\n",
        "    early_stopping=True,\n",
        "    validation_fraction=0.1,\n",
        "    random_state=42\n",
        ").fit(X_train, y_train)\n",
        "\n",
        "# --- 4. Prediction Generation ---\n",
        "dt_predictions = dt_model.predict(X_test)\n",
        "nn_predictions = nn_model.predict(X_test)\n",
        "\n",
        "# --- 5. Custom Comparison Function Definition (User's Structure) ---\n",
        "def compare_models_custom(y_test, dt_predictions, nn_predictions):\n",
        "    # Metric labels in the user's specified order\n",
        "    metrics = [\n",
        "        'Accuracy',\n",
        "        'Precision (Class 0 - Retained)', 'Precision (Class 1 - Churn)',\n",
        "        'F1-Score (Class 0 - Retained)', 'F1-Score (Class 1 - Churn)',\n",
        "        'Recall (Class 1 - Churn)', 'Recall (Class 0 - Retained)'\n",
        "    ]\n",
        "\n",
        "    # Calculate metrics for Decision Tree (DT)\n",
        "    dt_metrics = [\n",
        "        accuracy_score(y_test, dt_predictions),\n",
        "        precision_score(y_test, dt_predictions, pos_label=0),\n",
        "        precision_score(y_test, dt_predictions, pos_label=1),\n",
        "        f1_score(y_test, dt_predictions, pos_label=0),\n",
        "        f1_score(y_test, dt_predictions, pos_label=1),\n",
        "        recall_score(y_test, dt_predictions, pos_label=1),\n",
        "        recall_score(y_test, dt_predictions, pos_label=0)\n",
        "    ]\n",
        "\n",
        "    # Calculate metrics for Neural Network (NN)\n",
        "    nn_metrics = [\n",
        "        accuracy_score(y_test, nn_predictions),\n",
        "        precision_score(y_test, nn_predictions, pos_label=0),\n",
        "        precision_score(y_test, nn_predictions, pos_label=1),\n",
        "        f1_score(y_test, nn_predictions, pos_label=0),\n",
        "        f1_score(y_test, nn_predictions, pos_label=1),\n",
        "        recall_score(y_test, nn_predictions, pos_label=1),\n",
        "        recall_score(y_test, nn_predictions, pos_label=0)\n",
        "    ]\n",
        "\n",
        "    # Create a DataFrame to compare metrics\n",
        "    comparison_df = pd.DataFrame({\n",
        "        'Metric': metrics,\n",
        "        'Decision Tree': dt_metrics, # Renamed from 'Random Forest'\n",
        "        'Neural Network': nn_metrics\n",
        "    })\n",
        "\n",
        "    print(\"\\nModel Comparison (Metrics Table)\\n\")\n",
        "    print(comparison_df.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "    print()\n",
        "    return comparison_df\n",
        "\n",
        "# --- 6. Run Comparison and Plot Function Definition (User's Structure) ---\n",
        "comparison_df_custom = compare_models_custom(y_test, dt_predictions, nn_predictions)\n",
        "\n",
        "def plot_model_comparison_custom(df):\n",
        "    # Prepare data for plotting\n",
        "    df_plot = df.copy()\n",
        "    df_plot.set_index('Metric', inplace=True)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    ax = df_plot.plot(kind='bar', figsize=(12, 8), rot=45, ax=plt.gca(),\n",
        "                      color={'Decision Tree': '#2ECC71', 'Neural Network': '#3498DB'})\n",
        "\n",
        "    plt.title('Model Performance Comparison', fontsize=16)\n",
        "    plt.ylabel('Score', fontsize=12)\n",
        "    plt.xlabel('Metric', fontsize=12)\n",
        "    plt.xticks(ha='right')\n",
        "    plt.legend(loc='lower right', title='Model')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Add score labels to the bars\n",
        "    for container in ax.containers:\n",
        "        plt.bar_label(container, fmt='%.3f', padding=5, fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot custom model comparison\n",
        "plot_model_comparison_custom(comparison_df_custom)"
      ],
      "metadata": {
        "id": "GMiVZESycXAC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}